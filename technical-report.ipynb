{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# NBA Salary Predictor\n",
    "### By Adrian Rabadam and Michael Finch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Introduction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In looking for a fun dataset to focus this project on, Michael and I quickly realized we had a shared interest in the NBA and player statistics. Specifically, we also shared the belief that too many players in the NBA were being overpaid. Upon finding two solid datasets filled with player stats throughout history and player salaries over the years, we decided to make a classifier which predicted the range of a player's career average salary given a set of stats. To do this, we constructed four classifiers: k-Nearest Neighbors, Naive Bayes, a Decision Tree, and a Random Forest of Decision Trees. After running performance evaluations on these classifiers, the normal decision tree proved to be the most effective at predicting our classifier label. This ended up being the classifier we deployed through a Heroku app.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Aside from some standard, categorical player information, such as birthplace, draft team, and height, most of the attributes in this dataset are continuous. Standard attributes included a player's career points per game, assists per game, and rebounds per game. However, more advanced categorical stats included a player's PER (player efficiency rating), win shares, and true shooting percentage. The other dataset used contained only player career salaries, organized by a player's year in the nba. This dataset was converted to a categorical attribute and acted as our classifier label after inner joining it with the larger nba player dataset. Both datasets can be found at the source below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## NBA datasets source: https://data.world/datadavis/nba-salaries/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "After joining these two datasets, a total of 856 players were left in our final dataset (cut down from 4686 in the original dataset). Cleaning took into account the career games played, with players who played less than 164 games (2 full seasons) not making the cut. Furthermore, players drafted before 2000 were also not included, which notable ruled out a large amount of landmark players. The reason for this was to help the salary adjustment for inflation, as well as the natural change that has occurred in the past two decades concerning salary amount and the sort of value placed on players. Cleaning also involved removing any instances missing attribute values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Dataset statistics\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Visualizations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Classification Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In performing the classification procedure for each of our four classifiers, a similar method was applied to each. An X set was created by pulling the attributes of focus from the instances in the dataset, those being PER, win shares, and games played. A corresponding y_set was also created for the salary category ranks. For k-Nearest Neighbors, Naive Bayes, and the Decision Tree, a stratified 10 k-fold cross validation was performed to create a training set and test set. After fitting the training set on these three classifiers, prediction sets were made using the created X_test. These values were then compared to the actual, instance classifier labels in order to compute accuracies for each classifier. These accuracy values can be seen below:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "For the random forest classifier, a different, but similarly focused approach was taken. In fitting the X_set to the classifier, the data was split into a test set and a remainder set. The test set was stratified in order to help reflect the actual distribution in the dataset, just as was done with the previous three classifier. The remainder set was then used for training and validation for each decision tree. To create these sets, bagging was performed to randomly create a validation set (with replacement) with the rest of the remainder set making up a training set. Performance evaluation was then done on each of the N trees using the unique validation and training sets to compute accuracy values. The M most accurate trees were then stored in the classifier and are used to predict the salary labels from the passed in test sets. The classifier's performance as a whole was then measured by running its created test through it, posting an accuracy seen below:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Through this evaluation, the decision tree proved to be the most accurate and was used for deployment. The link for the Heroku app is provided below:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### NBA Salary Predictor Heroku App: https://nba-salary-app-adrian-michael.herokuapp.com/\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Conclusion \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "From the very beginning of finding the NBA players dataset, it was clear that we had a wide range of options when it came to making predictions. Pairing it with the salary dataset seemed like a good way to make the dataset applicable to an important aspect of sports organizations today. Given the comprehensiveness of the dataset, it was immediately difficult to decide how to cut it down, both in feature selection and data cleaning, which would be integral to our classification label since it is very dependent on the time period. However, once this dataset was cut down and approriate features were made, it was simple to design the classification process, especially with our past experience with these specific classifiers. The random forest classifier was certainly new, but it still dealt with practices and tools we were already familiar with (i.e. stratification, decision trees, testing/training), so it was important for us to keep that in min when approaching that classifier specifically. Despite this, it was clear that the decision tree perormed the best with the attributes we selected, and deciding that this was the model to deploy was easy given the accuracies we compared. To improve its performance in the future, more work could be done to cut down the players dataset, given just how skewed it was to the lower end of salary ranges. Furthermore, we could consider more weight on the more modern instances of players and statistics due to its reflection on the current salary market of the NBA and the nature of the classifier for prediction."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}
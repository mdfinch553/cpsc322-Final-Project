{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "\n",
    "import myutils\n",
    "importlib.reload(myutils)\n",
    "import myutils as myutils\n",
    "\n",
    "import dataPrepUtils\n",
    "importlib.reload(dataPrepUtils)\n",
    "import dataPrepUtils as dputils\n",
    "\n",
    "import mypytable\n",
    "importlib.reload(mypytable)\n",
    "from mypytable import MyPyTable \n",
    "\n",
    "import myclassifiers\n",
    "importlib.reload(myclassifiers)\n",
    "from myclassifiers import MyKNeighborsClassifier, MySimpleLinearRegressor, MyNaiveBayesClassifier, MyDecisionTreeClassifier\n",
    "\n",
    "import myevaluation\n",
    "importlib.reload(myevaluation)\n",
    "import myevaluation as myevaluation"
   ]
  },
  {
   "source": [
    "# Prepare data for fitting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 1, 1] 1\n[70000.0, 1609676.1, 3149352.2, 4689028.3, 6228704.4, 7768380.5, 9308056.6, 10847732.7, 12387408.8, 13927084.9, 15466761.0]\n"
     ]
    }
   ],
   "source": [
    "# Load data into a mypytable\n",
    "players_table = MyPyTable()\n",
    "players_table.load_from_file(\"cleaned-data.txt\")\n",
    "\n",
    "# create X_train and y_train\n",
    "# four attributes got: career_PER, career_PTS, career_G, draft_year, win shares\n",
    "# will test using win shares and PER\n",
    "per_col = players_table.get_column(\"career_PER\")\n",
    "pts_col = players_table.get_column(\"career_PTS\")\n",
    "games_col = players_table.get_column(\"career_G\")\n",
    "year_col = players_table.get_column(\"draft_year\")\n",
    "ws_col = players_table.get_column(\"career_WS\")\n",
    "# convert PER, PTS, and G to categorical\n",
    "per_cutoffs = dputils.compute_equal_width_cutoffs(per_col, 5)\n",
    "pts_cutoffs = dputils.compute_equal_width_cutoffs(pts_col, 5)\n",
    "games_cutoffs = dputils.compute_equal_width_cutoffs(games_col, 10)\n",
    "ws_cutoffs = dputils.compute_equal_width_cutoffs(ws_col, 5)\n",
    "categorical_per = myutils.convert_to_categorical(per_col, per_cutoffs)\n",
    "categorical_pts = myutils.convert_to_categorical(pts_col, pts_cutoffs)\n",
    "categorical_games = myutils.convert_to_categorical(games_col, games_cutoffs)\n",
    "categorical_ws = myutils.convert_to_categorical(ws_col, ws_cutoffs)\n",
    "X = []\n",
    "for i in range(len(categorical_per)):\n",
    "    temp = []\n",
    "    # will test using win shares and PER\n",
    "    #temp.append(year_col[i])\n",
    "    temp.append(categorical_pts[i])\n",
    "    #temp.append(categorical_per[i])\n",
    "    temp.append(categorical_games[i])\n",
    "    temp.append(categorical_ws[i])\n",
    "    X.append(temp)\n",
    "salaries = players_table.get_column(\"avg_salary\")\n",
    "salaries_cutoffs = dputils.compute_equal_width_cutoffs(salaries, 10)\n",
    "y = myutils.convert_to_categorical(salaries, salaries_cutoffs)\n",
    "player_names = players_table.get_column(\"name\")\n",
    "index = 271\n",
    "print(X[index], y[index])\n",
    "print(salaries_cutoffs)\n",
    "\n"
   ]
  },
  {
   "source": [
    "# kNN, Naive Bayes, Decision Tree Classifiers and Predictive Accuracies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=================================\nPredictive Accuracy\n=================================\nStratified 10-Fold Cross Validation\nk Nearest Neighbors: accuracy = 0.12792034215450415, error rate = 0.8720796578454959\nDecision Tree: accuracy = 0.7649024325046778, error rate = 0.23509756749532218\nNaive Bayes: accuracy = 0.36565089548249136, error rate = 0.6343491045175087\n\n"
     ]
    }
   ],
   "source": [
    "# perform stratified k-fold cross validation (k=10)\n",
    "\n",
    "X_train_folds, X_test_folds = myevaluation.stratified_kfold_cross_validation(X, y, 10)\n",
    "X_test = []\n",
    "X_train = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for fold in X_test_folds:\n",
    "    x_temp = []\n",
    "    y_temp = []\n",
    "    for i in range(len(fold)):\n",
    "        x_temp.append(X[fold[i]].copy())\n",
    "        y_temp.append(y[fold[i]])\n",
    "    X_test.append(x_temp)\n",
    "    y_test.append(y_temp)\n",
    "for fold in X_train_folds:\n",
    "    x_temp = []\n",
    "    y_temp = []\n",
    "    for i in range(len(fold)):\n",
    "        x_temp.append(X[fold[i]].copy())\n",
    "        y_temp.append(y[fold[i]])\n",
    "    X_train.append(x_temp)\n",
    "    y_train.append(y_temp)\n",
    "#print(X_test)\n",
    "# declare classifiers\n",
    "knn_classifier = MyKNeighborsClassifier()\n",
    "n_bayes_classifier = MyNaiveBayesClassifier()\n",
    "d_tree_classifier = MyDecisionTreeClassifier()\n",
    "\n",
    "# test/train with each fold\n",
    "knn_accuracies = []\n",
    "dtree_accuracies = []\n",
    "nbayes_accuracies = []\n",
    "knn_predicted_total = []\n",
    "dtree_predicted_total = []\n",
    "nbayes_predicted_total = []\n",
    "\n",
    "for k in range(len(X_test)):\n",
    "    # fit classifiers using X_train and y_train\n",
    "    knn_classifier.fit(X_train[k], y_train[k])\n",
    "    d_tree_classifier.fit(X_train[k], y_train[k])\n",
    "    X_train_copy = X_train[k].copy() # n_bayes needs a copy since it   modifies X_train\n",
    "    n_bayes_classifier.fit(X_train_copy, y_train[k])\n",
    "    #d_tree_classifier.print_decision_rules(attribute_names=[\"draft year\", \"career pts avg\", \"career per\", \"career games\"],  class_name=\"salary ranking\")\n",
    "    # make predictions\n",
    "    knn_predicted = knn_classifier.predict(X_test[k])\n",
    "    knn_predicted_total.append(knn_predicted)\n",
    "    dtree_predicted = d_tree_classifier.predict(X_test[k])\n",
    "    dtree_predicted_total.append(dtree_predicted)\n",
    "    nbayes_predicted = n_bayes_classifier.predict(X_test[k])\n",
    "    nbayes_predicted_total.append(nbayes_predicted)\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    count3 = 0\n",
    "    for i in range(len(knn_predicted)):\n",
    "        if knn_predicted[i] == y_test[k][i]:\n",
    "            count1 += 1\n",
    "        if dtree_predicted[i] == y_test[k][i]:\n",
    "            count2 += 1\n",
    "        if nbayes_predicted[i] == y_test[k][i]:\n",
    "            count3 += 1\n",
    "    knn_accuracies.append(count1 / len(knn_predicted))\n",
    "    dtree_accuracies.append(count2 / len(dtree_predicted))\n",
    "    nbayes_accuracies.append(count3 / len(nbayes_predicted))\n",
    "knn_accuracy = sum(knn_accuracies) / len(knn_accuracies)\n",
    "dtree_accuracy = sum(dtree_accuracies) / len(dtree_accuracies)\n",
    "nbayes_accuracy = sum(nbayes_accuracies) / len(nbayes_accuracies)\n",
    "# flatten total predicted lists\n",
    "knn_predicted_total = [item for sublist in knn_predicted_total for item in sublist]\n",
    "dtree_predicted_total = [item for sublist in dtree_predicted_total for item in sublist]\n",
    "nbayes_predicted_total = [item for sublist in nbayes_predicted_total for item in sublist]\n",
    "# print accuracies\n",
    "print(\"=================================\")\n",
    "print(\"Predictive Accuracy\")\n",
    "print(\"=================================\")\n",
    "print(\"Stratified 10-Fold Cross Validation\")\n",
    "print(\"k Nearest Neighbors: accuracy = \" + str(knn_accuracy) + \", error rate = \" + str(1 - knn_accuracy))\n",
    "print(\"Decision Tree: accuracy = \" + str(dtree_accuracy) + \", error rate = \" + str(1 - dtree_accuracy))\n",
    "print(\"Naive Bayes: accuracy = \" + str(nbayes_accuracy) + \", error rate = \" + str(1 - nbayes_accuracy))\n",
    "print()"
   ]
  },
  {
   "source": [
    "# Confusion Matrices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=================================\nConfusion Matrices\n=================================\nk-Nearest Neighbors (Stratified 10-Fold Cross Validation Results)\n      1    2    3    4    5    6    7    8    9    10    total    Recognition %\n--  ---  ---  ---  ---  ---  ---  ---  ---  ---  ----  -------  ---------------\n 1    3  131  179    8    0    2    9    9    0     1      342         0.877193\n 2    1   31   41    1    0    0    3    0    0     0       77        40.2597\n 3    1  134  160    8    0    0    6    4    0     0      313        51.1182\n 4    0   19   50    2    0    0    0    0    0     0       71         2.8169\n 5    0    0    0    0    0    0    0    0    0     0        0         0\n 6    0    5   17    1    0    1    3    1    0     0       28         3.57143\n 7    0    6   11    0    0    0    0    2    0     0       19         0\n 8    0    3    2    1    0    2    1    0    0     0        9         0\n 9    0    0    0    0    0    0    0    0    0     0        0         0\n10    0    5    1    0    0    1    1    0    0     0        8         0\n\nDecision Tree (Stratified 10-Fold Cross Validation Results)\n      1    2    3    4    5    6    7    8    9    10    total    Recognition %\n--  ---  ---  ---  ---  ---  ---  ---  ---  ---  ----  -------  ---------------\n 1  276   66    0    0    0    0    0    0    0     0      342          80.7018\n 2    0   77    0    0    0    0    0    0    0     0       77         100\n 3    3    0  310    0    0    0    0    0    0     0      313          99.0415\n 4    0   16   53    0    0    0    0    0    0     2       71           0\n 5    0    0    0    0    0    0    0    0    0     0        0           0\n 6    0    0    0    0    0   28    0    0    0     0       28         100\n 7    0    0    0    0    0    4   15    0    0     0       19          78.9474\n 8    0    0    0    1    0    5    0    3    0     0        9          33.3333\n 9    0    0    0    0    0    0    0    0    0     0        0           0\n10    0    0    0    6    0    0    0    0    0     2        8          25\n\nNaive Bayes (Stratified 10-Fold Cross Validation Results)\n      1    2    3    4    5    6    7    8    9    10    total    Recognition %\n--  ---  ---  ---  ---  ---  ---  ---  ---  ---  ----  -------  ---------------\n 1   59    0    0  283    0    0    0    0    0     0      342        17.2515\n 2    0   77    0    0    0    0    0    0    0     0       77       100\n 3  310    0    3    0    0    0    0    0    0     0      313         0.958466\n 4    2    1   53   15    0    0    0    0    0     0       71        21.1268\n 5    0    0    0    0    0    0    0    0    0     0        0         0\n 6    0    0    0    0    0   28    0    0    0     0       28       100\n 7    2    0    0    3    0    0   14    0    0     0       19        73.6842\n 8    0    0    0    3    0    1    0    5    0     0        9        55.5556\n 9    0    0    0    0    0    0    0    0    0     0        0         0\n10    0    0    0    0    0    0    0    2    0     6        8        75\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrices\n",
    "categories = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# flatten y_test\n",
    "y_test_total = [item for sublist in y_test for item in sublist]\n",
    "knn_matrix = myevaluation.confusion_matrix(y_test_total, knn_predicted_total,  categories)\n",
    "d_tree_matrix = myevaluation.confusion_matrix(y_test_total, dtree_predicted_total, categories)\n",
    "n_bayes_matrix = myevaluation.confusion_matrix(y_test_total, nbayes_predicted_total, categories)\n",
    "\n",
    "print(\"=================================\")\n",
    "print(\"Confusion Matrices\")\n",
    "print(\"=================================\")\n",
    "\n",
    "# create matrix header\n",
    "header = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"total\", \"Recognition %\"]\n",
    "\n",
    "# knn matrix\n",
    "for i in range(len(knn_matrix)): \n",
    "    total = sum(knn_matrix[i])\n",
    "    knn_matrix[i].append(total)\n",
    "    recognition = 0\n",
    "    if total != 0: \n",
    "        recognition = ((knn_matrix[i][i]/total) * 100)\n",
    "    knn_matrix[i].append(recognition)\n",
    "    knn_matrix[i].insert(0, (i + 1))\n",
    "print(\"k-Nearest Neighbors (Stratified 10-Fold Cross Validation Results)\")\n",
    "print(tabulate(knn_matrix, headers= header))\n",
    "print()\n",
    "\n",
    "# decision tree matrix\n",
    "for i in range(len(d_tree_matrix)): \n",
    "    total = sum(d_tree_matrix[i])\n",
    "    d_tree_matrix[i].append(total)\n",
    "    recognition = 0\n",
    "    if total != 0: \n",
    "        recognition = ((d_tree_matrix[i][i]/total) * 100)\n",
    "    d_tree_matrix[i].append(recognition)\n",
    "    d_tree_matrix[i].insert(0, (i + 1))\n",
    "print(\"Decision Tree (Stratified 10-Fold Cross Validation Results)\")\n",
    "print(tabulate(d_tree_matrix, headers= header))\n",
    "print()\n",
    "\n",
    "# naive bayes matrix\n",
    "for i in range(len(n_bayes_matrix)): \n",
    "    total = sum(n_bayes_matrix[i])\n",
    "    n_bayes_matrix[i].append(total)\n",
    "    recognition = 0\n",
    "    if total != 0: \n",
    "        recognition = ((n_bayes_matrix[i][i]/total) * 100)\n",
    "    n_bayes_matrix[i].append(recognition)\n",
    "    n_bayes_matrix[i].insert(0, (i + 1))\n",
    "print(\"Naive Bayes (Stratified 10-Fold Cross Validation Results)\")\n",
    "print(tabulate(n_bayes_matrix, headers= header))"
   ]
  }
 ]
}
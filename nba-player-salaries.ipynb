{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "\n",
    "import myutils\n",
    "importlib.reload(myutils)\n",
    "import myutils as myutils\n",
    "\n",
    "import dataPrepUtils\n",
    "importlib.reload(dataPrepUtils)\n",
    "import dataPrepUtils as dputils\n",
    "\n",
    "import mypytable\n",
    "importlib.reload(mypytable)\n",
    "from mypytable import MyPyTable \n",
    "\n",
    "import myclassifiers\n",
    "importlib.reload(myclassifiers)\n",
    "from myclassifiers import MyKNeighborsClassifier, MySimpleLinearRegressor, MyNaiveBayesClassifier, MyDecisionTreeClassifier\n",
    "\n",
    "import myevaluation\n",
    "importlib.reload(myevaluation)\n",
    "import myevaluation as myevaluation"
   ]
  },
  {
   "source": [
    "# Prepare data for fitting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2009.0, 4, 5, 5] 4\n[65000.0, 2631960.17, 5198920.33, 7765880.5, 10332840.67, 12899800.83, 15466761.0]\n"
     ]
    }
   ],
   "source": [
    "# Load data into a mypytable\n",
    "players_table = MyPyTable()\n",
    "players_table.load_from_file(\"cleaned-data.txt\")\n",
    "\n",
    "# create X_train and y_train\n",
    "# four attributes used: career_PER, career_PTS, career_G, draft_year\n",
    "per_col = players_table.get_column(\"career_PER\")\n",
    "pts_col = players_table.get_column(\"career_PTS\")\n",
    "games_col = players_table.get_column(\"career_G\")\n",
    "year_col = players_table.get_column(\"draft_year\")\n",
    "# convert PER, PTS, and G to categorical\n",
    "per_cutoffs = dputils.compute_equal_width_cutoffs(per_col, 5)\n",
    "pts_cutoffs = dputils.compute_equal_width_cutoffs(pts_col, 5)\n",
    "games_cutoffs = dputils.compute_equal_width_cutoffs(games_col, 10)\n",
    "categorical_per = myutils.convert_to_categorical(per_col, per_cutoffs)\n",
    "categorical_pts = myutils.convert_to_categorical(pts_col, pts_cutoffs)\n",
    "categorical_games = myutils.convert_to_categorical(games_col, games_cutoffs)\n",
    "X = []\n",
    "for i in range(len(categorical_per)):\n",
    "    temp = []\n",
    "    temp.append(year_col[i])\n",
    "    temp.append(categorical_pts[i])\n",
    "    temp.append(categorical_per[i])\n",
    "    temp.append(categorical_games[i])\n",
    "    X.append(temp)\n",
    "salaries = players_table.get_column(\"avg_salary\")\n",
    "salaries_cutoffs = dputils.compute_equal_width_cutoffs(salaries, 10)\n",
    "y = myutils.convert_to_categorical(salaries, salaries_cutoffs)\n",
    "player_names = players_table.get_column(\"name\")\n",
    "index = 271\n",
    "print(X[index], y[index])\n",
    "print(salaries_cutoffs)\n",
    "\n"
   ]
  },
  {
   "source": [
    "# kNN, Naive Bayes, Decision Tree Classifiers and Predictive Accuracies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "'1970.0' is not in list",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-97651b192aba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mdtree_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_tree_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mdtree_predicted_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtree_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mnbayes_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_bayes_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mnbayes_predicted_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbayes_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcount1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cpsc322-Final-Project/myclassifiers.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m    256\u001b[0m                     \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposteriors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposteriors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                     \u001b[0;31m#print(col)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                     \u001b[0mp_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m                     \u001b[0mp_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                     \u001b[0;31m#print(p_value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: '1970.0' is not in list"
     ]
    }
   ],
   "source": [
    "# perform stratified k-fold cross validation (k=10)\n",
    "\n",
    "X_train_folds, X_test_folds = myevaluation.stratified_kfold_cross_validation(X, y, 10)\n",
    "X_test = []\n",
    "X_train = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for fold in X_test_folds:\n",
    "    x_temp = []\n",
    "    y_temp = []\n",
    "    for i in range(len(fold)):\n",
    "        x_temp.append(X[fold[i]].copy())\n",
    "        y_temp.append(y[fold[i]])\n",
    "    X_test.append(x_temp)\n",
    "    y_test.append(y_temp)\n",
    "for fold in X_train_folds:\n",
    "    x_temp = []\n",
    "    y_temp = []\n",
    "    for i in range(len(fold)):\n",
    "        x_temp.append(X[fold[i]].copy())\n",
    "        y_temp.append(y[fold[i]])\n",
    "    X_train.append(x_temp)\n",
    "    y_train.append(y_temp)\n",
    "#print(X_test)\n",
    "# declare classifiers\n",
    "knn_classifier = MyKNeighborsClassifier()\n",
    "n_bayes_classifier = MyNaiveBayesClassifier()\n",
    "d_tree_classifier = MyDecisionTreeClassifier()\n",
    "\n",
    "# test/train with each fold\n",
    "knn_accuracies = []\n",
    "dtree_accuracies = []\n",
    "nbayes_accuracies = []\n",
    "knn_predicted_total = []\n",
    "dtree_predicted_total = []\n",
    "nbayes_predicted_total = []\n",
    "\n",
    "for k in range(len(X_test)):\n",
    "    # fit classifiers using X_train and y_train\n",
    "    knn_classifier.fit(X_train[k], y_train[k])\n",
    "    d_tree_classifier.fit(X_train[k], y_train[k])\n",
    "    X_train_copy = X_train[k].copy() # n_bayes needs a copy since it   modifies X_train\n",
    "    n_bayes_classifier.fit(X_train_copy, y_train[k])\n",
    "    #d_tree_classifier.print_decision_rules(attribute_names=[\"draft year\", \"career pts avg\", \"career per\", \"career games\"],  class_name=\"salary ranking\")\n",
    "    # make predictions\n",
    "    knn_predicted = knn_classifier.predict(X_test[k])\n",
    "    knn_predicted_total.append(knn_predicted)\n",
    "    dtree_predicted = d_tree_classifier.predict(X_test[k])\n",
    "    dtree_predicted_total.append(dtree_predicted)\n",
    "    nbayes_predicted = n_bayes_classifier.predict(X_test[k])\n",
    "    nbayes_predicted_total.append(nbayes_predicted)\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    count3 = 0\n",
    "    for i in range(len(knn_predicted)):\n",
    "        if knn_predicted[i] == y_test[k][i]:\n",
    "            count1 += 1\n",
    "        if dtree_predicted[i] == y_test[k][i]:\n",
    "            count2 += 1\n",
    "        if nbayes_predicted[i] == y_test[k][i]:\n",
    "            count3 += 1\n",
    "    knn_accuracies.append(count1 / len(knn_predicted))\n",
    "    dtree_accuracies.append(count2 / len(dtree_predicted))\n",
    "    nbayes_accuracies.append(count3 / len(nbayes_predicted))\n",
    "knn_accuracy = sum(knn_accuracies) / len(knn_accuracies)\n",
    "dtree_accuracy = sum(dtree_accuracies) / len(dtree_accuracies)\n",
    "nbayes_accuracy = sum(nbayes_accuracies) / len(nbayes_accuracies)\n",
    "# flatten total predicted lists\n",
    "knn_predicted_total = [item for sublist in knn_predicted_total for item in sublist]\n",
    "dtree_predicted_total = [item for sublist in dtree_predicted_total for item in sublist]\n",
    "nbayes_predicted_total = [item for sublist in nbayes_predicted_total for item in sublist]\n",
    "# print accuracies\n",
    "print(\"=================================\")\n",
    "print(\"Predictive Accuracy\")\n",
    "print(\"=================================\")\n",
    "print(\"Stratified 10-Fold Cross Validation\")\n",
    "print(\"k Nearest Neighbors: accuracy = \" + str(knn_accuracy) + \", error rate = \" + str(1 - knn_accuracy))\n",
    "print(\"Decision Tree: accuracy = \" + str(dtree_accuracy) + \", error rate = \" + str(1 - dtree_accuracy))\n",
    "print(\"Naive Bayes: accuracy = \" + str(nbayes_accuracy) + \", error rate = \" + str(1 - nbayes_accuracy))\n",
    "print()"
   ]
  },
  {
   "source": [
    "# Confusion Matrices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=================================\nConfusion Matrices\n=================================\nk-Nearest Neighbors (Stratified 10-Fold Cross Validation Results)\n      1    2    3    4    5    6    7    8    9    10    total    Recognition %\n--  ---  ---  ---  ---  ---  ---  ---  ---  ---  ----  -------  ---------------\n 1    0    0    0    0    0    0    0    0    0     0        0         0\n 2   15   17   16   17   17    7   14   12    1     6      122        90.3704\n 3    1    2    1    1    0    1    0    1    0     0        7         5.18519\n 4    1    0    0    0    1    1    2    0    0     0        5         3.7037\n 5    0    0    0    0    0    1    0    0    0     0        1         0.740741\n 6    0    0    0    0    0    0    0    0    0     0        0         0\n 7    0    0    0    0    0    0    0    0    0     0        0         0\n 8    0    0    0    0    0    0    0    0    0     0        0         0\n 9    0    0    0    0    0    0    0    0    0     0        0         0\n10    0    0    0    0    0    0    0    0    0     0        0         0\n\nDecision Tree (Stratified 10-Fold Cross Validation Results)\n      1    2    3    4    5    6    7    8    9    10    total    Recognition %\n--  ---  ---  ---  ---  ---  ---  ---  ---  ---  ----  -------  ---------------\n 1   14   16   14   16   14    9   14   10    0     5      112         82.963\n 2    1    1    1    1    4    0    2    1    0     0       11          8.14815\n 3    2    2    2    1    0    1    0    2    1     1       12          8.88889\n 4    0    0    0    0    0    0    0    0    0     0        0          0\n 5    0    0    0    0    0    0    0    0    0     0        0          0\n 6    0    0    0    0    0    0    0    0    0     0        0          0\n 7    0    0    0    0    0    0    0    0    0     0        0          0\n 8    0    0    0    0    0    0    0    0    0     0        0          0\n 9    0    0    0    0    0    0    0    0    0     0        0          0\n10    0    0    0    0    0    0    0    0    0     0        0          0\n\nNaive Bayes (Stratified 10-Fold Cross Validation Results)\n      1    2    3    4    5    6    7    8    9    10    total    Recognition %\n--  ---  ---  ---  ---  ---  ---  ---  ---  ---  ----  -------  ---------------\n 1    5    7    6   10    9    6    7    7    1     2       60        44.4444\n 2   11   10    9    5    8    2    8    3    0     3       59        43.7037\n 3    1    1    1    3    1    1    1    2    0     1       12         8.88889\n 4    0    0    1    0    0    1    0    1    0     0        3         2.22222\n 5    0    1    0    0    0    0    0    0    0     0        1         0.740741\n 6    0    0    0    0    0    0    0    0    0     0        0         0\n 7    0    0    0    0    0    0    0    0    0     0        0         0\n 8    0    0    0    0    0    0    0    0    0     0        0         0\n 9    0    0    0    0    0    0    0    0    0     0        0         0\n10    0    0    0    0    0    0    0    0    0     0        0         0\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrices\n",
    "categories = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# flatten y_test\n",
    "y_test_total = [item for sublist in y_test for item in sublist]\n",
    "knn_matrix = myevaluation.confusion_matrix(knn_predicted, y_test_total, categories)\n",
    "d_tree_matrix = myevaluation.confusion_matrix(dtree_predicted, y_test_total, categories)\n",
    "n_bayes_matrix = myevaluation.confusion_matrix(nbayes_predicted, y_test_total, categories)\n",
    "\n",
    "print(\"=================================\")\n",
    "print(\"Confusion Matrices\")\n",
    "print(\"=================================\")\n",
    "\n",
    "# create matrix header\n",
    "header = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"total\", \"Recognition %\"]\n",
    "\n",
    "# knn matrix\n",
    "for i in range(len(knn_matrix)):\n",
    "    knn_matrix[i].append(sum(knn_matrix[i]))\n",
    "total = 0\n",
    "for row in knn_matrix:\n",
    "    total += row[10]\n",
    "for i in range(len(knn_matrix)):\n",
    "    knn_matrix[i].append(knn_matrix[i][10]/total*100)\n",
    "    knn_matrix[i].insert(0, header[i])\n",
    "print(\"k-Nearest Neighbors (Stratified 10-Fold Cross Validation Results)\")\n",
    "print(tabulate(knn_matrix, headers= header))\n",
    "print()\n",
    "\n",
    "# decision tree matrix\n",
    "for i in range(len(d_tree_matrix)):\n",
    "    d_tree_matrix[i].append(sum(d_tree_matrix[i]))\n",
    "total = 0\n",
    "for row in d_tree_matrix:\n",
    "    total += row[10]\n",
    "for i in range(len(d_tree_matrix)):\n",
    "    d_tree_matrix[i].append(d_tree_matrix[i][10]/total*100)\n",
    "    d_tree_matrix[i].insert(0, header[i])\n",
    "print(\"Decision Tree (Stratified 10-Fold Cross Validation Results)\")\n",
    "print(tabulate(d_tree_matrix, headers= header))\n",
    "print()\n",
    "\n",
    "# naive bayes matrix\n",
    "for i in range(len(n_bayes_matrix)):\n",
    "    n_bayes_matrix[i].append(sum(n_bayes_matrix[i]))\n",
    "total = 0\n",
    "for row in n_bayes_matrix:\n",
    "    total += row[10]\n",
    "for i in range(len(n_bayes_matrix)):\n",
    "    n_bayes_matrix[i].append(n_bayes_matrix[i][10]/total*100)\n",
    "    n_bayes_matrix[i].insert(0, header[i])\n",
    "print(\"Naive Bayes (Stratified 10-Fold Cross Validation Results)\")\n",
    "print(tabulate(n_bayes_matrix, headers= header))"
   ]
  }
 ]
}